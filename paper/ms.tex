\documentclass[article]{jss}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{enumerate}
\usepackage{dsfont}

\newcommand{\dnest}{\pkg{DNest4}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Brendon J. Brewer\\The University of Auckland\And 
        Daniel Foreman-Mackey\\University of Washington}
\title{\pkg{DNest4}: Diffusive Nested Sampling in
\proglang{C++} and \proglang{Python}}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Brendon J. Brewer, Daniel Foreman-Mackey} %% comma-separated
\Plaintitle{DNest4: An implementation of Diffusive Nested Sampling in
C++11 and Python} %% without formatting
\Shorttitle{\pkg{DNest4}: Diffusive Nested Sampling} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{In probabilistic (Bayesian) inferences, we typically want to compute
properties of the posterior distribution, describing knowledge of
unknown quantities in the context of a particular dataset and the assumed
prior information. The marginal likelihood, also known as the ``evidence'',
is a key quantity in Bayesian model selection. The Diffusive Nested Sampling algorithm, a variant of Nested Sampling, is a powerful tool for generating
posterior samples and estimating marginal likelihoods. It is effective at
solving complex problems including many where the posterior distribution is
multimodal or has strong dependencies between variables.
\pkg{DNest4} is an open source (MIT licensed),
multi-threaded implementation of this algorithm in
\proglang{C++11},
along with associated utilities including: i)
a \pkg{Python} package allowing basic use without \proglang{C++} coding;
ii) \pkg{RJObject}, a class template for finite mixture models;
iii) Experimental support for models implemented in \proglang{Julia}; and
iv) An experimental \proglang{Python} tool to
generate \pkg{C++} code from a model specification.
In this paper we demonstrate \pkg{DNest4} usage through examples including
simple Bayesian data analysis, finite mixture models, and Approximate
Bayesian Computation.
}

\Keywords{bayesian inference, markov chain monte carlo,
metropolis algorithm, bayesian computation, nested sampling, \proglang{c++11},
\proglang{python}}
\Plainkeywords{bayesian inference, markov chain monte carlo,
metropolis algorithm, bayesian computation, nested sampling, c++11, python} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Brendon J. Brewer\\
  Department of Statistics\\
  The University of Auckland\\
  Private Bag 92019\\
  Auckland, 1142\\
  New Zealand\\
  E-mail: \email{bj.brewer@auckland.ac.nz}\\
  URL: \url{https://www.stat.auckland.ac.nz/~brewer/}
}

\newcommand{\params}{\theta}
\newcommand{\data}{D}
\newcommand{\dobs}{D_{\rm obs}}

\begin{document}
\maketitle

%% Need this after the abstract
%\setlength{\parindent}{0pt}
%\setlength{\parskip}{8pt}

\section{Introduction}
Bayesian inference, where probability theory is used to describe degrees of
logical implication or subjective certainty, provides a powerful general basis
for data analysis \citep{ohagan, sivia}. The result of such
an analysis is typically
posterior probabilities of various hypotheses, or
a joint posterior probability distribution for the values of unknown
parameters.

In compact but standard notation, the posterior
posterior distribution for parameters $\params$ given data $\data$, within
the context of prior information $M$, is
\begin{align}
p(\params | \data, M) &=
\frac{p(\params | M)p(\data | \params, M)}{p(\data | M)}
\end{align}
or
\begin{align}
\textnormal{posterior} &=
\frac{\textnormal{prior} \times \textnormal{likelihood}}
     {\textnormal{marginal likelihood}}.
\end{align}

If prior information $I$ (dropped hereafter)
implies a set of possible `models' $\{M_i\}$,
rather than a single one $M$, the posterior model probabilities are given by
\begin{align}
P(M_i | \data) &=
\frac{P(M_i)p(\data | M_i)}{\sum_j P(M_j)p(\data | M_j)}
\end{align}
where
\begin{align}
p(\data | M_j) &= \int p(\theta_j | M_j)p(\data | \theta_j, M_j) \, d\theta_j
\end{align}
is the marginal likelihood of model $j$, equal to the expected value of the
likelihood function with respect to the prior distribution.
This kind of calculation is often
called ``model selection'' or ``model averaging''.

When discussing computational matters, the prior distribution for parameters
is
often written $\pi(\theta)$, the likelihood $L(\theta)$,
and the marginal likelihood $Z$. A popular alternative name for the marginal
likelihood, which emphasizes its role in Bayesian model averaging,
is the ``evidence''.

Nested Sampling \citep[NS;][]{skilling} is a Monte Carlo method whose main
aim is to calculate $Z$. However, it can also be used to generate samples
to represent the posterior distribution $\pi(\theta)L(\theta)/Z$, or
any other distribution proportional to
$\pi(\theta)\Phi\left[L(\theta)\right]$ where $\Phi$ is any monotonic function.
This latter property makes NS particularly useful for statistical mechanics
calculations \citep{2009arXiv0906.3544P, 2015arXiv150303404B}, where the
``canonical'' family of distributions proportional to
$\pi(\theta)L(\theta)^\beta$ is of interest. In such applications,
$L(\theta)$ is usually equivalent to
$\exp(-\textnormal{energy})$. NS is particularly efficient for this, since
only a single run (exploring regions of higher and higher $L$) is needed, and different canonical
distributions can be obtained by re-weighting the output points.

A defining feature of NS is that it works with a sequence of
{\em constrained prior} distributions, proportional to $\pi$ but
restricted to regions of the parameter space where $L(\theta)$
is above some threshold $\ell$:
\begin{align}
p(\theta; \ell) &=
\frac{\pi(\theta)\mathds{1}\left[L(\theta) > \ell\right]}{X(\ell)}
\label{eqn:constrained_prior}
\end{align}
where
\begin{align}
X(\ell) &= \int \pi(\theta) \mathds{1}\left[L(\theta) > \ell\right] \, d\theta
\end{align}
is the amount of prior mass which has likelihood greater than $\ell$, and
$\mathds{1}()$ is the indicator function which takes the value 1 if the
argument is true and 0 otherwise.
In the standard NS framework, the sequence of $\ell$ values is selected
so that $X(\ell)$ shrinks by a factor $\approx e^{-1/N}$ per iteration, where
$N$ is the number of particles used. This geometric compression of the
parameter space is a defining feature of NS.

Sampling from the constrained priors (Equation~\ref{eqn:constrained_prior})
is required, and Markov Chain Monte Carlo (MCMC) is a popular method of doing
this, although alternatives exist \citep[e.g.][]{multinest, 2015MNRAS.453.4384H}.
Diffusive Nested Sampling \citep[DNS][]{dnest} is an alternative to NS for
problems where MCMC is the only viable sampling method. DNS is based on the
Metropolis algorithm. DNS evolves one or more particles in the parameter space, along with
an integer index variable $j$ for each particle,
to explore the following joint distribution:
\begin{align}
p(\theta, j) &= p(j)p(\theta | j)\\
&= w_j \times
\frac{\pi(\theta)\mathds{1}\left[L(\theta) > \ell_j\right]}{X(\ell_j)}.
\label{eqn:target_distribution}
\end{align}
where the $\{\ell_j\}$ are a sequence of increasing likelihood thresholds
or {\em levels}, and
$\ell_0 = 0$, and $\{w_j\}$ is the marginal distribution for $j$.
The marginal distribution for $\theta$ is then a {\em mixture} of
constrained priors:
\begin{align}
p(\theta) &=
\pi(\theta)\sum_{j=0}^{j_{\rm max}}
\frac{w_j\mathds{1}\left[L(\theta) > \ell_j\right]}{X(\ell_j)}.
\label{eqn:mixture_of_constrained_priors}
\end{align}
The DNS algorithm consists of two main stages. In the first stage,
the particle(s) are initialized from the prior $\pi(\theta)$, equivalent
to the mixture of constrained priors with a single level whose likelihood
threshold is $-\infty$. The mixture of constrained priors evolves by adding new levels
(see \citet{dnest} for details). In this stage,
the mixture weights $\{w_j\}$ are set according to
\begin{align}
w_j &\propto \exp(j/\lambda),\label{eqn:weighting}
\end{align}
where $\lambda$ is a scale length.
This enhances the probability that particles stay close to the
highest likelihood regions seen.
The second stage sets the mixture weights to be approximately
uniform ($w_j \propto 1$), with some tweaks described by \citet{dnest}.

The mixture of constrained priors tends to be easier to sample than the
posterior, as the prior is always a mixture component, allowing the
MCMC chain to mix between different modes in some circumstances. The marginal
likelihood estimate can also be more accurate than standard MCMC-based NS
\citep{dnest}, as less information is discarded.
DNS has been applied several times in astrophysics
\citep[e.g.][]{2014MNRAS.445.3055P, 2015ApJ...810...66H, 2015MNRAS.448.3206B}
and was recently used in a biological application \citep{salmonella}.

There are several ways of using \pkg{DNest4}. After installing the software
(Section~\ref{sec:installation}), you can implement a model as
a \proglang{C++} class
(Section~\ref{sec:models}) and compile it to create an executable file
to run \pkg{DNest4} on that problem. This method offers full control over the
design of your class, and allows the opportunity of optimizing
performance by preventing a full re-computation of the log-likelihood when
only a small subset of the parameters have been changed.

Alternatively, the \proglang{Python}
bindings (Section~\ref{sec:python_bindings}) allow you
to specify a model class in \proglang{Python}, and run \pkg{DNest4} entirely
in the \proglang{Python} interpreter without having to invoke the \proglang{C++}
compiler.

\section{Markov Chain Monte Carlo}\label{sec:mcmc}
DNS is build upon the Metropolis-Hastings algorithm.
In this algorithm, the acceptance probability $\alpha$
is given by
\begin{align}
\alpha &= \min\left(1,
\frac{q(\params'|\params)}{q(\params | \params')}
\frac{\pi(\params')}{\pi(\params)}\frac{L(\params')}{L(\params)}
\right)
\end{align}
where $q(\theta' | \theta)$ is the proposal distribution used to generate
a new position $\theta'$ from the current position $\theta$. Often,
$q$ is {\em symmetric} so the $q$ terms cancel in the acceptance probability.

In DNS, the target distribution is not the posterior but rather
the joint distribution in Equation~\ref{eqn:target_distribution}.
Moves of $\theta$ are done keeping $j$ fixed, so we only need
to consider the Metropolis acceptance probability for fixed $j$,
i.e. with respect to a single constrained prior like
Equation~\ref{eqn:constrained_prior}.
Hence, the appropriate acceptance probability
for a proposed move from $\theta$ to $\theta'$ is
\begin{align}
\alpha &= \min\left[1,
\frac{q(\params'|\params)}{q(\params | \params')}
\frac{\pi(\params')}{\pi(\params)}
\mathds{1}\left(L(\params') > \ell_j\right)
\right]
\label{eqn:log_hastings}
\end{align}
where $\ell_j$ is the likelihood threshold for level $j$.

For convenience later on, we 
separate the prior and proposal-related terms from
the likelihood-related term, and write the former as
\begin{align}
H = \frac{q(\params'|\params)}{q(\params | \params')}
\times \frac{\pi(\params')}{\pi(\params)}
\end{align}
so the acceptance probability becomes
\begin{align}
\alpha &= \min\left[1,
H\times
\mathds{1}\left(L(\params') > \ell_j\right)
\right]
\end{align}


%The \pkg{DNest4} \code{Sampler} class handles the likelihood check,
%while the \code{perturb(DNest4::RNG\&)} member function handles the
%rest of the terms. The value returned from \code{perturb(DNest4::RNG\&)}
%must be
%for your problem.



%\subsection{Diffusive Nested Sampling}



\section{Dependencies and installation}\label{sec:installation}

\subsection{Unix-like operating systems}
The following instructions apply to Unix-like operating systems such as
GNU/Linux, Mac OS X, and FreeBSD.
\pkg{DNest4} can be obtained from the \pkg{git} repository located at
\begin{center}
{\tt https://github.com/eggplantbren/DNest4/}\\
\end{center}
and is licensed under the
MIT license. To obtain and compile \pkg{DNest4},
you require \pkg{git} and a recent version of the GNU
\proglang{C++} compiler, \pkg{g++}. The \proglang{Python}
packages \pkg{NumPy}, \pkg{matplotlib},
\pkg{Pandas}, and \pkg{Cython} are also needed.
To download and compile \pkg{DNest4}
the following steps are sufficient:
\begin{CodeChunk}
\begin{CodeInput}
git clone https://github.com/eggplantbren/DNest4
cd DNest4/code
make
cd ../python
python setup.py install
\end{CodeInput}
\end{CodeChunk}

We recommend you create an environment variable called \code{DNEST4\_PATH}
and set it to the directory {\em above} the \pkg{DNest4} directory. Then,
if the examples or templates from the \pkg{DNest4} repository are copied
to any other location on your system, their Makefiles will continue to work.

\subsection{Microsoft Windows}


\section{Running DNest4}\label{sec:running}
To demonstrate \pkg{DNest4},
we will use a simple linear regression example where the
sampling distribution is
\begin{align}
y_i | m, b, \sigma &\sim \textnormal{Normal}(mx_i + b, \sigma^2)
\end{align}
and the priors are
\begin{align}
m &\sim \textnormal{Normal}(0, 1000^2)\\
b &\sim \textnormal{Normal}(0, 1000^2)\\
\ln\sigma &\sim \textnormal{Uniform}(-10, 10).
\end{align}
These are naive diffuse priors and do not have any special status.
This model was implemented in \proglang{C++}
(see Section~\ref{sec:models} for details).
The dataset is shown in Figure~\ref{fig:regression_lines}
and the code is included in the {\tt code/Examples/StraightLine}
subdirectory. A simplified version of the
code is explained in Section~\ref{sec:models}.
To execute \pkg{DNest4} on this problem, go to this directory and
execute {\tt main}. The output to the screen
should contain information about levels and ``saving particles to disk''.
After 5000 particles have been saved to the disk, the run should terminate.

\section{Output files}
The executable {\tt main} is responsible for the exploration part of the
DNS algorithm (i.e. running the MCMC chain, building
levels, and then exploring all the levels). It creates three text output files,
{\tt sample.txt}, {\tt sample\_info.txt}, and {\tt levels.txt}.

The first output
file, {\tt sample.txt}, contains a sampling of parameter values that
represents the {\it mixture of constrained priors} (the target distribution
used in DNS), {\bf not} the
posterior distribution. Each line of {\tt sample.txt} represents a point in
parameter space. In the linear example, there are three parameters
($m$, $b$, and $\sigma$), so there
are three columns in {\tt sample.txt}.
Each time a point is saved to {\tt sample.txt}, \pkg{DNest4} prints
the message ``Saving a particle to disk. N = ...''.

The second output file, {\tt sample\_info.txt}, should have the same number of
rows as {\tt sample.txt}, because it contains metadata about the samples in
{\tt sample.txt}. The first
column is the index $j$, which tells us which ``level'' the particle was in
when it was saved. Level 0 represents the prior, and higher levels represent
more constrained versions of the prior.
The second column is the log-likelihood value, and the third column is
the likelihood ``tiebreaker'', which allows Nested Sampling to work when
there is a region in parameter space with nonzero prior probability where the
likelihood is constant. The final column tells us which thread the particle
belonged to: when you use \dnest~in multithreaded mode, each thread
is responsible for evolving one or more walkers.

The third output file, {\tt levels.txt}, contains information about the levels
that were built during the run. The first column has estimates of the $\log(X)$
values of the levels, i.e. how compressed they are relative to the prior, in
units of nats. For example, if a level has $\log(X) = -1.02$, its likelihood
value encloses $\exp(-1.02) \approx 36.1\%$ of the prior mass.

The second column contains the log likelihoods of the levels.
The first level, with a $\log(X)$ value of 0 and a log likelihood of
$-10^{308}$ (basically ``minus infinity''), is simply the prior. The third
column has the ``tiebreaker'' values for the levels, which again are not
particularly useful unless your problem has likelihood plateaus. The fourth
and fifth columns are the number of accepted proposals and the total number
of proposals that have occurred within each level, which are useful for
monitoring the Metropolis acceptance ratio as a function of level.
The final two columns, called ``exceeds'', and ``visits'', are used to refine
the estimates of the level compressions (and hence the $\log(X)$ values of
the levels in column 1), as discussed in Section 3 of the
paper. The visits column counts the number of times a level (level $j$, say)
has been visited, but only starts counting after the next level ($j+1$) has been created. The exceeds column counts the number of times a particle that was
in level $j$ had a likelihood that exceeded that of level $j+1$.

\section{Postprocessing}\label{sec:postprocessing}
The output files themselves are typically not immediately useful.
The goal of running
NS is usually to obtain posterior samples and the marginal likelihood $Z$,
whereas {\tt sample.txt} only contains samples from the mixture of constrained
priors. Additional
post-processing is required. This can be achieved by running the following
\proglang{Python} function\footnote{Alternatively, the file
{\tt showresults.py} in the example directory runs this function, and then
calls the code in {\tt display.py} to create a further plot shown in
Figure~\ref{fig:regression_lines}.}:

\begin{CodeChunk}
\begin{CodeInput}
import dnest4.classic
dnest4.classic.postprocess()
\end{CodeInput}
\end{CodeChunk}
This produces the three diagnostic plots in Figures~\ref{fig:fig1},
\ref{fig:fig2}, and~\ref{fig:fig3}, along with the following output:
\begin{CodeChunk}
\begin{CodeOutput}
log(Z) = -175.528264138
Information = 15.1944947225 nats.
Effective sample size = 745.819862383
\end{CodeOutput}
\end{CodeChunk}
These are the natural log of the marginal likelihood, the
information
\begin{align}
\mathcal{H} &= \int p(\theta|D, I)
\ln\left[\frac{p(\theta | D, I)}{p(\theta | I)}\right] \, d\theta,
\end{align}
which quantifies the degree to which $D$ restricted the
range of possible $\theta$ values,
and the effective sample size,
or number of saved particles with significant posterior weight.
The \code{postprocess} function also saves a file,
{\tt posterior\_sample.txt}, containing posterior samples (one per row).
Unfortunately, it is harder to compute justified error bars on $\ln(Z)$
in DNS than it is in standard NS.
%The \code{postprocess} function does include some options
%for calculating error bars, but they are not used by default,
%and we do not describe them here.
%Hence, the zero-sized error bars on $\ln(Z)$ and $\mathcal{H}$ should
%be ignored.

The \code{postprocess} function can be called while \pkg{DNest4} is running.
This is helpful for monitoring the progress of a run, by inspecting the
output plots.

\begin{figure}[ht!]
\begin{minipage}{7.5cm}
\centering
\includegraphics[width=7cm]{figures/fig1.pdf}
\caption{The level $j$ of the saved particles over time.
Typically, this will trend upwards until all the levels have
been created, and then diffuse evenly throughout all the levels.
\label{fig:fig1}}
\end{minipage}\hspace{0.5cm}
\begin{minipage}{7.5cm}
\centering
\includegraphics[width=8cm]{figures/fig2.pdf}
\caption{{\bf Top panel}: The estimated compression factor between subsequent
levels, expressed as $\ln(X_{i+1}/X_{i})$. {\bf Bottom panel}:
The Metropolis acceptance fraction as a function of level.
\label{fig:fig2}}
\end{minipage}
\end{figure}

\begin{figure}[ht!]
\begin{minipage}{7.5cm}
\includegraphics[width=7cm]{figures/fig3.pdf}
\caption{{\bf Top panel}: The log-likelihood curve, showing the relationship
between log-likelihood and the enclosed prior mass.
{\bf Bottom panel}: Posterior weights of the saved particles.
For a successful run, there should be a clear peak, and saved particles
to the left of this plot should have insignificant posterior weight compared
to those in the peak.
\label{fig:fig3}}
\end{minipage}\hspace{0.5cm}
\begin{minipage}{7.5cm}
\includegraphics[width=7cm]{figures/regression_lines.pdf}
\caption{Regression lines drawn from the posterior.
\label{fig:regression_lines}}
\end{minipage}
\end{figure}

\subsection{Options}\label{sec:options}
A plain-text file called {\tt OPTIONS} resides in the directory from which you
execute a run. This file contains numerical parameters controlling the
DNS algorithm. Here are the contents of {\tt OPTIONS} for the linear
regression example:

\begin{CodeChunk}
\begin{CodeInput}
# File containing parameters for DNest4
# Put comments at the top, or at the end of the line.
5       # Number of particles
10000   # new level interval
10000   # save interval
100     # threadSteps - pooling interval
0       # maximum number of levels (0 ==> automatic)
10      # Backtracking scale length (lambda in the paper)
100     # Equal weight enforcement. Beta in the paper
5000    # Maximum number of saves (0 ==> run forever)
\end{CodeInput}
\end{CodeChunk}

Additional options are available on the command line. These are
described in Appendix~\ref{sec:command_line_options}.

\subsection{Number of particles}
The first option is the number of particles, here set to five.
If you use more particles, the same amount of CPU time will be spent evolving more particles,
so each one will not be evolved as far. On most problems, five is a sensible
default value. On complex problems where the likelihood function has
a challenging structure, more particles are useful, but it is usually better
to run in multi-threaded mode (see Appendix~\ref{sec:command_line_options}).

\subsection{New level interval}
The new level interval controls how quickly \dnest~creates new levels. In this
example, this is set to 10,000, so a new level will be created once 10,000
MCMC steps have resulted in
10,000 likelihood values above the current top level.
It is difficult to give a sensible default for this
quantity because it depends on the complexity of the problem (basically,
how good the Metropolis proposals are at exploring the target distribution).
However, 10,000 will work for many problems, so we suggest it as a sensible
default. Higher values are slower, but more fail-safe.

\subsection{Save interval}
The save interval controls how often \dnest~writes a model to the output
files; what is usually called ``thinning''. Saving more frequently
(i.e. a smaller save interval) is usually better. However, this can result
in
big output files if your model prints a lot of parameters to {\tt sample.txt}.
causing the postprocessing to take a long time and/or a lot of RAM.
A default suggestion, used in the example, is to set the save interval to the
same value as the new level interval.

\subsection{Thread steps}
The ``thread steps'' parameter controls how frequently separate threads pool
their information about the levels (when running in multi-threaded mode,
see Appendix~\ref{sec:command_line_options}). It should be set to a moderate
value, but should also be a small fraction of the new level interval and the
save interval. 100 is a suggested default value that should work without
problems in the vast majority of cases.

\subsection{Maximum number of levels}
As the name suggests, this tells \pkg{DNest4} how many levels to create, and
therefore controls the factor by which the parameter space is ultimately
compressed. An appropriate value for this quantity depends on the specific
model and dataset at hand --- typically, a larger numbers of parameters
and larger (more informative) datasets will lead to a larger value of
$\mathcal{H}$, and therefore need more levels.

In the initial phase of DNS when levels are being created, the particles
move to the left in Figure~\ref{fig:fig3}, increasing likelihood $L$ and
decreasing prior mass $X$. The posterior distribution is concentrated
where the rate of increase of $\ln(L)$ and the rate of decrease of
$\ln(X)$ are approximately equal.
Figure~\ref{fig:fig3} is the most useful diagnostic
plot for setting the correct
maximum number of levels. A clear peak should be visible in the posterior
weights plot in the lower panel, such that moving further to the left would not
add any more particles with comparable weight to those in the peak.

As described by \citet{skilling}, there is no guarantee in principle that
another peak might have appeared had a run continued for longer. These
{\em phase changes} are more common in statistical mechanics problems than
in data analysis problems, but can appear in the latter
\citep[e.g.][]{rjobject, 2015MNRAS.448.3206B}.

Alternatively, \pkg{DNest4} can try to determine the maximum number of levels
automatically, if you set the maximum number of levels to 0. This works well
on problems where the MCMC exploration is efficient. When it fails, this
is detectable as the posterior weights plot (lower panel of
Figure~\ref{fig:fig3}) will peak at the left end of its domain. However,
such a failed run may still be useful as it can be used to suggest an order of
magnitude for the required number of levels. For example, if the automatic
setting results in 150 levels and is later seen to fail, it might be worth
a try to set the maximum number of levels to, say, $1.3 \times 150 = 195$.

\subsection{Backtracking scale length}
The backtracking scale length, denoted by $\lambda$, appeared in
Equation~\ref{eqn:weighting}, and controls the degree to which particles
are allowed to ``backtrack'' down in level during the first stage of DNS
when levels are being built. Higher values are more fail-safe, but
make it take longer to create the levels. The value 10 used in the linear
regression example is a suitable default value that should work in almost all
cases. In simple problems where MCMC exploration is easy, lower values
from 1 to 5 work sufficiently well.

\subsection{Equal weight enforcement}
This value is the parameter $\beta$ described in \citet{dnest}, and compensates
for imprecision in the spacing of the levels, so that the desired mixture
weights $w_j \propto 1$ are achieved during the second stage of the DNS
algorithm. The value 100 is recommended.

\subsection{Maximum number of saves}
This controls the length of a \pkg{DNest4} run, in units of saved particles
in {\tt sample.txt}, which represent the mixture of constrained priors.
The number of posterior samples is always less than this. In most applications
5,000 (as in the linear regression example) provides enough posterior
samples (typically a few hundred) for sufficiently accurate posterior
summaries. However, if you want to plot smooth-looking posterior histograms,
you'll need to increase this value.

If you set the maximum number of saves to zero, \pkg{DNest4} will run until
you terminate it manually.

\section{Implementing models}\label{sec:models}
The ``classic'' method of implementing models in \pkg{DNest4} is by
writing a \proglang{C++} class, an object of which represents a
point in your parameter space.

To run \pkg{DNest4} on any particular problem, such as this linear regression
example, the user needs to define a \proglang{C++} class to specify the
model. Specifically, an object of the class represents a point in the
model's parameter space. Member functions are defined which generate
the object's parameters from the prior, make proposal steps, evaluate the
likelihood, and so on. The sampler calls these member functions while
executing a run.

For the simple linear regression example, we will call the class
{\tt StraightLine}. The member variables representing the
unknown parameters are defined in the header file {\tt StraightLine.h}:

\begin{CodeChunk}
\begin{CodeInput}
class StraightLine
{
    private:
        double m, b, sigma;
};
\end{CodeInput}
\end{CodeChunk}

The class must also define and implement the following member functions:
\begin{enumerate}[(i)]
\item \code{void from\_prior(DNest4::RNG\& rng)}, which generates parameter
        values from the prior;
\item \code{double perturb(DNest4::RNG\& rng)}, which proposes a
        change to the parameter values, and returns $\ln(H)$ as defined in
        Equation~\ref{eqn:log_hastings};
\item \code{double log\_likelihood() const}, which evaluates the log of
        the likelihood function;
\item \code{void print(std::ostream\& out) const}, which prints parameters of
        interest to the given output stream; and
\item \code{std::string description() const}, which returns a \proglang{C++}
        string naming the parameters printed by \code{print(std::ostream\&) const}.
        This string is printed (after a comment character \#) at the top of
        the output file.
\end{enumerate}
These are all described (using the linear regression example) in the
following subsections.

%%\subsection{generate}

%\section{Python package}

%% Assign to DFM

%\section{Examples}
% Reasonably simple examples

\subsection{Generating from the prior}
The member function used to generate straight line parameters from the
prior is:
\begin{CodeChunk}
\begin{CodeInput}
void StraightLine::from_prior(DNest4::RNG& rng)
{
   // Naive diffuse prior
   m = 1E3*rng.randn();
   b = 1E3*rng.randn();

   // Log-uniform prior
   sigma = exp(-10.0 + 20.0*rng.rand());
}
\end{CodeInput}
\end{CodeChunk}

This generates $m$, $b$, and $\sigma$ from their joint prior. In this case,
the priors are all independent, so this reduces to generating the parameters
each from their own prior distribution. For convenience,
\pkg{DNest4} provides an \code{RNG} class to represent random number
generators. The \code{RNG} class is just a convenience wrapper for the
random number generators built into \proglang{C++11}.
As you might expect, there are
\code{rand()} and \code{randn()} member functions to generate
double precision values
from a Uniform$(0,1)$ and Normal$(0,1)$ distribution respectively.

\subsection{Proposal moves}
The \code{perturb} member function for the straight line model is:
\begin{CodeChunk}
\begin{CodeInput}
double StraightLine::perturb(DNest4::RNG& rng)
{
    double log_H = 0.0;

    // Proposals must be consistent with the prior
    // Choose which of the three parameters to move
    int which = rng.rand_int(3);

    if(which == 0)
    {
        // log_H takes care of the prior ratio
        // i.e. log_H = log(pi(theta')/pi(theta))
        log_H -= -0.5*pow(m/1E3, 2);

        // Take a step
        m += 1E3*rng.randh();

        // log_H takes care of the prior ratio
        log_H += -0.5*pow(m/1E3, 2);
    }
    else if(which == 1)
    {
        log_H -= -0.5*pow(b/1E3, 2);
        b += 1E3*rng.randh();
        log_H += -0.5*pow(b/1E3, 2);
    }
    else
    {
        // Proposal for a parameter with a log-uniform
        // prior takes the log of the parameter,
        // takes a step with respect to a uniform prior,
        // then takes the exp of the parameter
        sigma = log(sigma);
        sigma += 20.0*rng.randh();

        // Wrap proposed value back into the
        // interval allowed by the prior
        DNest4::wrap(sigma, -10.0, 10.0);
        sigma = exp(sigma);
    }

    return log_H;
}
\end{CodeInput}
\end{CodeChunk}

This first chooses a random integer from $[0, 3)$ using the
\code{rand\_int(int)} member function of the \code{DNest4::RNG} class.
This determines which of the three parameters
$(m, b, \sigma)$ is modified. In this example, there are no proposals
that modify more than one of the parameters at a time, and all proposals
are ``random walk'' proposals that add a perturbation
(drawn from a symmetric distribution) to the current value.

\subsection{Proposals for single parameters}
The proposal for $m$ involves adding a perturbation to the current
value using the line

\begin{CodeChunk}
\begin{CodeInput}
m += 1E3*rng.randh();
\end{CodeInput}
\end{CodeChunk}

A challenge using MCMC for standard Nested Sampling is that the target
distribution is not static --- it gets compressed over time. Similarly, in
the first stage of DNS the target distribution gets compressed (as levels are
added), and in the second stage the target distribution is a mixture of
distributions that have been compressed to varying degrees.
This makes it difficult to tune step-sizes as you would when using
the standard Metropolis algorithm to sample the posterior distribution.

Rather than trying to adapt proposal distributions as a function of level,
it is much simpler to just use heavy-tailed proposals which have some
probability of making a jump of appropriate size. This may seem slightly
wasteful of CPU time, but it saves a lot of human time.
In simple experiments, we have found that heavy-tailed proposals are
about as efficient as slice sampling \citep{slice}, but much easier to
implement. The following procedure generates
$x$ from a heavy-tailed distribution:

\begin{enumerate}
\item Generate $a, b, c \sim$ Normal$(0, 1)$
\item Define $t := c/\sqrt{(a^2 + b^2)/2}$
\item Generate $n \sim$ Normal$(0, 1)$
\item Set $x := 10^{1.5 - 3|t|}n$
\end{enumerate}
The variable $t$ has a student-$t$ distribution with 2 degrees of freedom.
Overall, this procedure generates values $x$
with a maximum scale of tens--hundreds, down to
a minimum scale of about $10^{-30}$ with 99\% probability, by virtue
of the $t$-distribution's heavy tails.
For convenience, the \code{RNG} class contains a member function \code{randh()}
to generate values from this distribution.
The factor of \code{1E3} is included because it is a measure of the prior
width. Therefore, this proposal will attempt moves whose maximum order of
magnitude is a bit wider than the prior (since it would be very surprising
if any bigger moves were needed), and will propose moves a few orders of
magnitude smaller with moderate probability. We recommend using
this strategy (a measure of prior width, multiplied by \code{randh()}) as
a default proposal that works well in almost all problems.

Recall that for Nested Sampling, the Metropolis acceptance probability,
excluding the term for the likelihood, is
\begin{align}
H = \frac{q(\params'|\params)}{q(\params | \params')}
\times \frac{\pi(\params')}{\pi(\params)}.
\end{align}
When implementing a model class, the
\code{perturb(DNest4::RNG\&)}
member function must return the logarithm of this value.
Since the prior for $m$ is a normal distribution with
mean zero and standard deviation $1000$, $H$ is
\begin{align}
H &= \frac{\exp\left[-\frac{1}{2}(m'/1000)^2\right]}
{\exp\left[-\frac{1}{2}(m/1000)^2\right]}.
\end{align}
This explains the use of the \code{log\_H} variable.

In the example, the proposal for $\sigma$ is implemented by taking advantage
of the uniform prior for $\ln(\sigma)$. So $\sigma$ is transformed by
taking a logarithm, a proposal move is made (that satisfies detailed balance
with respect to a uniform distribution), and then $\sigma$ is exponentiated
again. The step for the uniform prior between -10 and +10
uses the following code:
\begin{CodeChunk}
\begin{CodeInput}
sigma += 20.0*rng.randh();
DNest4::wrap(sigma, -10.0, 10.0);
\end{CodeInput}
\end{CodeChunk}
The factor of 20 accounts for the prior width, and
the \code{wrap(double\&, double, double)} function uses the modulo operator
to construct periodic boundaries. For example, if the perturbation results
in a value of 10.2, which is outside the prior range, the value is modified to
$-9.8$.
The \code{wrap} function has no return value and works by modifying its
first argument, which is passed by reference.
Alternatively, the log-uniform prior, which has density proportional
to $1/\sigma$, could have been used directly by not using the log/exponential
trick and adding $\ln\left[(1/\sigma')/(1/\sigma)\right]$ to the
return value. However, this isn't recommended for a distribution like this
which covers several orders of magnitude, because the appropriate scale size
for the proposal is less clear. This is likely to cause inefficient
sampling.

\subsection{Consistency of prior and proposal}
It is imperative that \code{from_prior} and
\code{perturb}
be consistent with each other, and that each implements
the prior distributions that you want to use. One technique
for testing this is to sample the prior for a long time
(by setting the maximum number of levels to 1) and inspect
{\tt sample.txt} to ensure that each parameter is exploring
the prior correctly.

\subsection{Log-likelihood}
The log-likelihood code is standard:
\begin{CodeChunk}
\begin{CodeInput}
double StraightLine::log_likelihood() const
{
    // Grab the dataset
    const std::vector<double>& x = Data::get_instance().get_x();
    const std::vector<double>& y = Data::get_instance().get_y();

    // Variance
    double var = sigma*sigma;

    // Conventional gaussian sampling distribution
    double log_L = 0.0;
    double mu;
    for(size_t i=0; i<y.size(); ++i)
    {
        mu = m*x[i] + b;
        log_L += -0.5*log(2*M_PI*var) - 0.5*pow(y[i] - mu, 2)/var;
    }

    return log_L;
}
\end{CodeInput}
\end{CodeChunk}
The dataset is assumed to be accessible inside this function. In the
regression example, this is achieved by having a
\code{Data} class to represent
datasets. Since there will usually only be one dataset,
the {\em singleton pattern} (a class of which there is one instance
accessible from anywhere) is recommended.

\subsection{Parameter output}
The print and description functions are very simple:
\begin{CodeChunk}
\begin{CodeInput}
void StraightLine::print(std::ostream& out) const
{
    out<<m<<' '<<b<<' '<<sigma;
}

std::string StraightLine::description() const
{
    return std::string("m, b, sigma");
}
\end{CodeInput}
\end{CodeChunk}
The print function specifies that the parameters
$m$, $b$, and $\sigma$ are printed a single line
(of {\tt sample.txt}) and are separated by spaces (the
\code{postprocess} function assumes this is the case).

\subsection{Running the sampler}
The file {\tt main.cpp} contains the \code{main()} function which
is executed after compiling and linking. The contents of {\tt main.cpp}
for the linear regression example are:

\begin{CodeChunk}
\begin{CodeInput}
#include <iostream>
#include "Data.h"
#include "DNest4/code/DNest4.h"
#include "StraightLine.h"

using namespace std;
using namespace DNest4;

int main(int argc, char** argv)
{
    Data::get_instance().load("road.txt");
    start<StraightLine>(argc, argv);
    return 0;
}
\end{CodeInput}
\end{CodeChunk}


The first line of {\tt main()} loads the data into its global instance
(so it can be accessed from within the log-likelihood function)
and the second line uses a \code{start} template function to construct
and run the sampler.

\section{Finite Mixture Models with RJObject}
Mixture models are a useful way of representing realistic prior information
in Bayesian data analysis. To reduce the amount of effort needed to
implement mixture models in DNS, \citet{rjobject} implemented
a template class called \code{RJObject} to handle the MCMC moves
required. The RJ in \code{RJObject} stands for Reversible Jump \citep{green}, as
\code{RJObject} implements birth and death moves for mixture
models with an unknown number of components. An updated version of
\code{RJObject} is included in \pkg{DNest4}.

If $N$ is the number of components, $x_i$ denotes the vector of parameters
of the $i$th component, and $\alpha$ is the vector of hyperparameters, the prior
can be factorised via the product rule, giving
\begin{align}
p\left(N, \alpha, \left\{x_i\right\}_{i=1}^N\right)
&= p(N)p(\alpha | N)p\left(\left\{x_i\right\}_{i=1}^N | \alpha, N\right).
\end{align}
The specific assumptions of \pkg{RJObject} are that this simplifies to
\begin{align}
p\left(N, \alpha, \left\{x_i\right\}_{i=1}^N\right)
&= p(N)p(\alpha)
\prod_{i=1}^N
p\left(x_i | \alpha\right).\label{eqn:rjobject}
\end{align}
That is, the prior for the hyperparameters is independent of the number of
components, and each component is independent and identically
distributed given the hyperparameters.
A probabilistic graphical model (PGM) is showing this dependence
structure is shown in Figure~\ref{fig:rjobject_pgm}. There are no observed
data nodes here, but if such a structure forms part of a
Bayesian model, an \code{RJObject} object within your model class
can encapsulate this part of the model.

\begin{figure}[ht!]
\begin{center}
\hspace*{-2cm}\includegraphics[width=0.4\textwidth]{figures/rjobject_pgm.pdf}
\caption{A PGM showing the kind of prior information the \code{RJObject}
template class expresses.
Figure created using Daft ({\tt http://daft-pgm.org}).\label{fig:rjobject_pgm}}
\end{center}
\end{figure}

\citet{rjobject} described the motivation for \code{RJObject} and some details
about the Metropolis proposals underlying it. Here, we demonstrate how to
implement a finite mixture model using \code{RJObject}.
This example can be found in the
\begin{center}
{\tt code/Examples/RJObject\_1DMixture}
\end{center}
directory.

\subsection{An example mixture model}
Consider a sampling distribution
for data $D=\{D_1, D_2, ..., D_n\}$ which is a mixture of $N$ gaussians
with means $\{\mu_j\}$, standard deviations $\{\sigma_j\}$, and
mixture weights $\{w_j\}$. The likelihood for the $i$th data point is
\begin{align}
p(D_i | N, \{\mu_j\}, \{\sigma_j\}, \{w_j\}) &=
\sum_{j=1}^N \frac{w_j}{\sigma_j\sqrt{2\pi}}
\exp\left[-\frac{1}{2\sigma_j^2}\left(D_i - \mu_j\right)^2\right].
\end{align}
Colloquially, one might say the data were 'drawn from' a mixture of
$N$ normal distributions, and we want to infer $N$ along with the
properties of those normal distributions.

Making the connection with Equation~\ref{eqn:rjobject} and
Figure~\ref{fig:rjobject_pgm}, the ``components'' are the gaussians,
the gaussian parameters are $x_j = \{\mu_j, \sigma_j, w_j\}$
and hyperparameters $\alpha$ may be used to help specify
a sensible joint prior for the gaussian parameters.
To implement this model for \pkg{DNest4}, the model
class only needs to contain an instance of an
\code{RJObject}, like so:

\begin{CodeChunk}
\begin{CodeInput}
class MyModel
{
	private:
        DNest4::RJObject<MyConditionalPrior> gaussians;
....
\end{CodeInput}
\end{CodeChunk}
where the template argument \code{<MyConditionalPrior>}
is a class implementing the prior for the hyperparameters
$\alpha$ and the form of the conditional prior $p(x_i | \alpha)$.

The specific prior for $N$ was
\begin{align}
p(N) \propto \frac{1}{N+1}
\end{align}
for $N \in \{1, 2, ..., 100\}$.

We used the following priors for the hyperparameters:
\begin{align}
a_\mu &\sim \textnormal{Uniform}(-1000, 1000)\\
\ln b_\mu &\sim \textnormal{Uniform}(-10, 10)\\
a_{\ln\sigma} &\sim \textnormal{Uniform}(-10, 10)\\
b_{\ln\sigma} &\sim \textnormal{Uniform}(0, 5)\\
b_{\ln W} &\sim \textnormal{Uniform}(0, 5)
\end{align}
Location parameters $a$, scale parameters $b$.

The priors for the parameters given the hyperparameters were:
\begin{align}
\mu_j &\sim \textnormal{Laplace}(a_\mu, b_\mu)\\
\ln\sigma_j &\sim \textnormal{Laplace}(a_{\ln\sigma}, b_{\ln\sigma})\\
\ln W_j &\sim \textnormal{Laplace}(0, b_{\ln W}).
\end{align}

A Laplace (or bi-exponential)
distribution with location parameter $a$ and scale parameter
$b$ has density
\begin{align}
p(x | a, b) &= \frac{1}{2}\exp\left(-\frac{1}{b}|x - a|\right).
\end{align}

The normalized weights are $w_k = W_k/\sum w_j$.


Some illustrative posterior samples are plotted
in Figure~\ref{fig:galaxies}.

\begin{figure}
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/galaxies.pdf}
\caption{\label{fig:galaxies}}
\end{center}
\end{figure}


\section{Approximate Bayesian Computation}
Nested Sampling can be used to solve Approximate Bayesian Computation (ABC)
problems elegantly and efficiently.
Also known (misleadingly) as likelihood-free inference,
ABC
is a set of Monte Carlo techniques for approximating the posterior distribution
without having to evaluate the likelihood function $L(\theta)$. Instead, 
the user must be able to cheaply
generate simulated data sets from the sampling distribution $p(D|\theta, M)$.
Since a sampling distribution must be specified, it is not that there is
no likelihood function (indeed, a sampling distribution and
a data set imply a particular likelihood function), rather that we cannot
evaluate it cheaply and therefore cannot use MCMC.

All Bayesian updating conditions on the truth of a proposition. We sometimes
speak and use notation as if we're conditioning on the value of a variable, for
example by writing the posterior distribution as
$p(\theta | D, M)$. However,
this is shorthand for $p(\theta | D = D_{\rm observed}, M)$.
In the prior state of knowledge, the statement
$D = D_{\rm observed}$ could have been either
true or false in the prior state of knowledge, but it is known to be true
in the posterior state of knowledge.
In the case of ``continuous data'' (really a continuous {\it space of
possibilities for the data before we learned it}) we condition on a
proposition like $(D \in \mathcal{R})$ where $\mathcal{R}$ is a region, and
then implicitly take a limit as the size of $\mathcal{R}$ goes to zero.

A simple ``rejection sampling'' version of
ABC works by sampling the joint prior distribution for the parameters and
data
\begin{align}
p(\theta, D | M) &= p(\theta | M)p(D | \theta, M)
\end{align}
and rejecting samples for which $D \neq D_{\rm observed}$, so that the
samples represent
\begin{align}
p(\theta, D | D = D_{\rm observed}, M) &\propto p(\theta | M)p(D | \theta, M)
\mathds{1}\left[D = D_{\rm observed}\right].
\end{align}
The marginal distribution for $\theta$ is also the conditional distribution
$p(\theta | D = D_{\rm observed}, M)$, that is,
the posterior\footnote{Incidentally, this usage of the {\em joint} posterior
distribution for the parameters {\em and the data} provides a bridge
connecting Bayesian updating to maximum entropy updating \citep{caticha,giffin}.}.

This approach is rarely usable in practice because the probability of
generating a dataset that matches the observed one is extremely low.
To work around this, we replace the proposition
$D = D_{\rm observed}$ with a logically
weaker one (i.e. one that is implied by $D = D_{\rm observed}$ but does not
imply it). This is usually done by defining a few {\em summary statistics}
$s_1(D), s_2(D), ..., s_n(D)$, which hopefully capture most of the relevant
information in the data.
Then, a discrepancy function
$\rho$ is defined, measuring how different a simulated dataset $D$ is from
the real one $D_{\rm observed}$, in terms of the summary statistics:
\begin{align}
\rho\left(\{s_1(D), ..., s_n(D)\}; \{s_1(D_{\rm observed}), ..., s_n(D_{\rm observed})\}\right)
\end{align}
The analysis then proceeds by Monte Carlo sampling the
joint posterior for $\theta$ and $D$
conditional on the logically weaker proposition
\begin{align}
\rho\left(D; D_{\rm observed}\right) < \epsilon
\end{align}
where $\epsilon$ is some small number. With this proposition, the
rejection rate will still
typically be very high, but lower than with $D = D_{\rm observed}$. 

The main challenges associated with ABC are:
\begin{enumerate}[(i)]
\item The choice of summary statistics $s_1(D), ..., s_n(D)$
\item The choice of distance function $\rho()$
\item How to choose the value of $\epsilon$, or how to change it as a run
progresses
\item How to make algorithms more efficient than rejection sampling.
\end{enumerate}
Challenges (i) and (ii) are Bayesian in nature, i.e. they relate to the very
definition of the posterior distribution itself.
On the other hand, challenges 3 and 4 are about the computational
implementation. Most ABC analyses are done using Sequential Monte Carlo
\citep[SMC][]{delmoral}.


%\begin{table}[ht!]
%\centering
%\small
%\begin{tabular}{|l|l|l|}
%\hline
%Bayesian computation		&		Statistical mechanics		&		ABC\\
%\hline
%Parameter space	$\Theta$	&		Phase space	$\Omega$ 			& Product space $\Theta \times \mathcal{D}$\\
%Posterior $p(\params | D,I)$   &  Canonical distribution $p(\boldsymbol{x}; T)$     & \\ 
%Marginal likelihood $P(D|I)$	&	Partition function $Z(T)$	&   Marginal likelihood $p(D\in | I)$\\
%\hline
%\end{tabular}
%\caption{\it The relationship between standard Bayesian computation, statistical
%mechanics, and ABC. In each case Monte Carlo methods are used to calculate
%integrals over a space. In standard Bayesian computation, it is the parameter
%space of a model that is usually of interest, whereas in ABC it is the space
%of possible parameter values {\it and} data sets.
%\label{tab:relation}}
%\end{table}


%\begin{figure}[ht!]
%\centering
%\includegraphics[scale=0.5]{figures/joint.pdf}
%\caption{\it The joint prior for parameters $\params$ and data $\data$.
%\label{fig:joint}}
%\end{figure}


%\section{Parameterising the data space}
%In standard MCMC-based ABC, proposal moves are made by first proposing a
%change to the parameters (from $\params$ to $\params'$), and then generating
%a mock dataset $\data'$ from $p(\data | \params')$. As a Metropolis proposal
%for exploring the product space $\Theta \times \mathcal{D}$ this is a very
%aggressive choice, since the proposed value of the
%dataset $\params'$ is likely to be very different from the previous one.
%One of the most elementary pieces of advice we receive when learning the
%Metropolis algorithm is to be careful about how ambitious our proposal
%distributions are, since tiny and huge proposal moves are both very
%inefficient. The performance of MCMC-based ABC can therefore be improved by
%alternative choices of proposal distribution.

%In some cases, we might be able to find efficient proposal distributions for exploring $\Theta \times \mathcal{D}$ by having insight into the particular
%problem we're working on. However, there are also techniques that are
%completely general in that they should work on any ABC-type problem.

%Consider the process of generating a mock dataset. Whatever else is involved,
%this process will involve calls to an underlying random number generator.
%Perhaps a function {\tt rand()}, generating variables from a Uniform(0, 1)
%distribution, is called $n$ times in the course of generating a dataset.
%Usually, the simulation process has the property that, if $\theta'$ is
%close to $\theta$, then the same sequence of random numbers returned by
%{\tt rand()} would produce a dataset $\data'$ that is very similar to $\data$.
%This suggests an alternative parameterisation of
%the product space $\Theta\times\mathcal{D}$: instead of using the one that
%naturally describes the data, we can use a coordinate system defined by
%$\theta$ together with $\{u_1, ..., u_n\}$, the $n$ uniform random numbers
%used to construct a mock dataset.

%In this alternative coordinate system, a proposed move
%to change $\params$ while keeping
%$\{u_i\}$ fixed results in a proposed new dataset that is similar to the
%previous one, assuming the change to $\params$ is small. The standard procedure
%of generating an entirely new mock dataset each step is now viewed as a
%proposal where $\params$ is moved {\it and all of the $u_i$ coordinates are
%re-generated from their iid uniform prior}.

\section{Python Bindings}\label{sec:python_bindings}

{\bf To be written by Dan FM}


\section*{Acknowledgements}
John Veitch (Birmingham)
and Jorge Alarcon Ochoa (Rensselaer Polytechnic Institute)
provided helpful comments on an early
version of the manuscript.
It is a pleasure to thank Anna Pancoast (Harvard),
Ewan Cameron (Oxford), David Hogg (NYU), and Daniela Huppenkothen (NYU)
for valuable discussions. BJB was supported by a Marsden Fast-Start grant
from the Royal Society of New Zealand.

\begin{thebibliography}{99}
\bibitem[Baldock et al.(2015)]{2015arXiv150303404B} Baldock, R.~J.~N., 
P{\'a}rtay, L.~v.~B., Bart{\'o}k, A.~P., Payne, M.~C., Cs{\'a}nyi, G.\ 
2015.\ Determining pressure-temperature phase diagrams of materials.\ ArXiv 
e-prints arXiv: 1503.03404. 

\bibitem[\protect\citeauthoryear{Brewer, P{\'a}rtay,
\& Cs{\'a}nyi}{2011}]{dnest} Brewer B.~J., P{\'a}rtay L.~B., Cs{\'a}nyi G., 2011,
Statistics and Computing, 21, 4, 649-656. arXiv:0912.2380

\bibitem[Brewer(2014)]{rjobject} Brewer, B.~J.\ 2014.\ Inference for Trans-dimensional Bayesian Models with Diffusive Nested Sampling.\ ArXiv e-prints arXiv:1411.3921.

\bibitem[Brewer and Donovan(2015)]{2015MNRAS.448.3206B} Brewer, B.~J., Donovan, C.~P.\ 2015.\ Fast Bayesian inference for exoplanet discovery in radial velocity data.\ Monthly Notices of the Royal Astronomical Society 448, 3206-3214. 

\bibitem[Caticha and Giffin(2006)]{caticha} Caticha, A., Giffin, A.\ 2006.\ Updating Probabilities.\ Bayesian Inference and Maximum Entropy Methods In Science and Engineering 872, 31-42. 

\bibitem[Del Moral et al(2012)]{delmoral}
Del Moral, P., Doucet, A. and Jasra, A., 2012. An adaptive sequential Monte Carlo method for approximate Bayesian computation. Statistics and Computing, 22(5), pp.1009-1020.

\bibitem[Dybowski et al(2015)]{salmonella}
Dybowski, Richard, et al. Single passage in mouse organs enhances the survival and spread of Salmonella enterica. Journal of The Royal Society Interface 12.113 (2015): 20150702.

\bibitem[\protect\citeauthoryear{Feroz, Hobson,
\& Bridges}{2009}]{multinest} Feroz F., Hobson M.~P., Bridges M., 2009, MNRAS, 398, 1601

\bibitem[Giffin and Caticha(2007)]{giffin} Giffin, A., Caticha, A.\ 2007.\ Updating Probabilities with Data and Moments.\ Bayesian Inference and Maximum Entropy Methods in Science and Engineering 954, 74-84. 

\bibitem[\protect\citeauthoryear{Green}{1995}]{green}
Green, P.~J., 1995, Reversible Jump Markov Chain Monte Carlo Computation and Bayesian Model Determination, Biometrika 82 (4): 711732.

\bibitem[Handley et al.(2015)]{2015MNRAS.453.4384H} Handley, W.~J., Hobson, M.~P., Lasenby, A.~N.\ 2015.\ POLYCHORD: next-generation nested sampling.\ Monthly Notices of the Royal Astronomical Society 453, 4384-4398. 

\bibitem[Huppenkothen et al.(2015)]{2015ApJ...810...66H} Huppenkothen, D., Brewer, B.~J., Hogg, D.~W., Murray, I., Frean, M., Elenbaas, C., Watts, A.~L., Levin, Y., van der Horst, A.~J., Kouveliotou, C.\ 2015.\ Dissecting Magnetar Variability with Bayesian Hierarchical Models.\ The Astrophysical Journal 810, 66. 

\bibitem[Neal(2003)]{slice}
Neal, R.M., 2003. Slice sampling. Annals of statistics, pp.705-741.

\bibitem[\protect\citeauthoryear{O'Hagan and Forster}{2004}]{ohagan}
O'Hagan, A., Forster,~J., 2004, Bayesian inference. London: Arnold.

\bibitem[Pancoast et al.(2014)]{2014MNRAS.445.3055P} Pancoast, A., Brewer, B.~J., Treu, T.\ 2014.\ Modelling reverberation mapping data - I. Improved geometric and dynamical models and comparison with cross-correlation results.\ Monthly Notices of the Royal Astronomical Society 445, 3055-3072.

\bibitem[\protect\citeauthoryear{Sivia and Skilling}{2006}]{sivia} Sivia, 
D.~ S., Skilling, J., 2006, Data Analysis: A Bayesian Tutorial, 2nd 
Edition, Oxford University Press

\bibitem[P{\'a}rtay et al.(2009)]{2009arXiv0906.3544P} P{\'a}rtay, L.~B., 
Bart{\'o}k, A.~P., Cs{\'a}nyi, G.\ 2009.\ Efficient sampling of atomic 
configurational spaces.\ ArXiv e-prints arXiv: 0906.3544. 

\bibitem[\protect\citeauthoryear{Skilling}{2006}]{skilling} Skilling, J., 2006, Nested Sampling for General Bayesian Computation, Bayesian Analysis 4, pp. 833-860.

\end{thebibliography}

\appendix
\section{Command Line Options}\label{sec:command_line_options}
The following command line options are available.\\

\code{-o <filename>}\\
This option loads the \pkg{DNest4} options from the specified file, allowing
an alternative to the default OPTIONS.\\

\code{-s <seed>}\\
This seeds the random number generator with the specified value. If unspecified, the system time is used.\\

\code{-d <filename>}\\
Load data from the specified file, if required.\\

\code{-c <value>}\\
Standard DNS creates levels with a volume ratio of approximately
$e\approx 2.71828$. To use a different value, such as 10, use this option.
In our experience, \code{-c 10} tends to work better than the default
value on problems with a large information $\mathcal{H}$.
The output units remain in nats.
This option is incompatible with setting the maximum number of levels to 0
(automatic) in the OPTIONS file.
\\

\code{-t <num\_threads>}\\
Run on the specified number of threads. The default is 1.

\section{Specifying models in Python with dnest4.builder}


\section{Specifying models in Julia}
Experimental support for model specification in the
\proglang{Julia} language is provided, with an example given in the
code/Templates/JuliaModel directory.
Set an enviroment variable {\tt JULIA\_LIB\_PATH} to the directory on your
system that contains the libraries {\tt libjulia.so} and
{\tt sys.so}. Set another environment variable {\tt JULIA\_INCLUDE\_PATH}
to the directory where the \proglang{Julia} header files are located
(do not include the final {\tt julia} directory in this path).

The log likelihood is specified in {\tt julia\_model.jl}, as a function
called {\tt log\_likelihood} that takes a {\tt Vector::Float64} as an argument
and returns a {\tt Float64}. You should assume that the priors for the
parameters are independent Uniform(0, 1) distributions (sensible default
proposals are used). To use a different prior, transform the parameters inside
your {\tt log\_likelihood} function before using them.
You may add other functions to {\tt julia\_model.jl}, for example to load
a dataset to refer to in your {\tt log\_likelihood}. The example in
the repository is the ``SpikeSlab'' likelihood from \citet{dnest}.

You can compile the model by invoking {\tt make}
from the {\tt JuliaModel} directory.
Only a single thread is supported when running \proglang{Julia}
models.




\end{document}

